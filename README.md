## Introduction

Meta Crawler is designed to crawl over file systems and networks to create semantic meta tags, enabling agents to navigate and structure our growing collection of files. This project focuses on document classification and relevance, leveraging AI to handle the otherwise impossible task of organizing vast amounts of data. Our prototype not only classifies documents (public, internal, confidential, restricted) but also provides confidence ratings for each classification. The system becomes more powerful as more files are crawled, ensuring the latest and most relevant versions are used. The ultimate goal is to add more meta tags, functioning as SEO for future AI agents to retrieve accurate information.

![Meta Crawler](metacrawler.png)
